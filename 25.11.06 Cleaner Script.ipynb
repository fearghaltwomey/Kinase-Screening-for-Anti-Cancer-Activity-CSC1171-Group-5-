{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afa45e2a-8813-4fa9-91ca-b751795c6945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from lightgbm) (2.2.6)\n",
      "Requirement already satisfied: scipy in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from lightgbm) (1.16.0)\n",
      "Requirement already satisfied: xgboost in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from xgboost) (2.2.6)\n",
      "Requirement already satisfied: scipy in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from xgboost) (1.16.0)\n",
      "Requirement already satisfied: catboost in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (1.2.8)\n",
      "Requirement already satisfied: graphviz in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from catboost) (3.10.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from catboost) (2.2.6)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from catboost) (2.3.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: plotly in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from catboost) (6.4.0)\n",
      "Requirement already satisfied: six in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from matplotlib->catboost) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from matplotlib->catboost) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from matplotlib->catboost) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from matplotlib->catboost) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from matplotlib->catboost) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from matplotlib->catboost) (3.2.3)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\fearg\\anaconda3\\envs\\dcu\\lib\\site-packages (from plotly->catboost) (2.10.2)\n"
     ]
    }
   ],
   "source": [
    "# Pips\n",
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install lightgbm\n",
    "!pip install xgboost\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66eff209-810e-4f1e-8a84-e8aa9fbd1805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function / Package Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import friedmanchisquare\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "import warnings; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81c80e5c-f6a8-40b4-bd07-627a43174c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Imports / Manipulation\n",
    "df1 = pd.read_csv(r\"Representative_kinases (1)\\Representative_kinases\\Rep_kinases_dataset.csv\", sep= \"\t\")\n",
    "df2 = pd.read_csv(r\"Dark Matter (I'm not running descriptors again).csv\")\n",
    "\n",
    "# Sort Kinases, Merge, etc.\n",
    "# end with df_Kinase / df_KinaseGroup (~x20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b9f8484-151a-44dc-93fa-8fdee02bf6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Functions\n",
    "def clean_df1(df1):\n",
    "    df1 = df1[df1[\"p_standard_type\"] == \"pIC50\"]\n",
    "    df1[\"SMILES\"] = df1[\"NonstereoAromaticSMILES\"]\n",
    "    df1[\"Value\"] = df1[\"p_value\"]\n",
    "    df1[\"Class\"] = 1\n",
    "    df1[\"Kinase\"] = df1[\"Kinase_name\"]\n",
    "    df1[\"Group\"] = df1[\"Kinase_group\"]    \n",
    "    dfx = df1[[\"SMILES\", \"Class\", \"Value\", \"Kinase\", \"Group\"]]\n",
    "    del df1\n",
    "    \n",
    "    return dfx\n",
    "\n",
    "def clean_df2(df2):\n",
    "    df2[\"Value\"] = 0\n",
    "    df2[\"Kinase\"] = \"n/a\"\n",
    "    df2[\"Group\"]= \"n/a\"\n",
    "    dfy = df2[[\"SMILES\", \"Class\", \"Value\", \"Kinase\", \"Group\"]]\n",
    "    del df2\n",
    "    \n",
    "    return dfy\n",
    "    \n",
    "def validate_df(df):\n",
    "    required_cols = {\"SMILES\", \"Class\", \"Value\", \"Kinase\", \"Group\", \"Fingerprint\"}\n",
    "    if df.shape[0] <= 1000:\n",
    "        raise ValueError(f\"Not enough data: {df.shape[0]} elements\")\n",
    "    if set(df.columns) != required_cols:\n",
    "        raise TypeError(f\"Incorrect dataframe structure: \\nProvided {list(df.columns)} \\nExpected {list(required_cols)}\")\n",
    "\n",
    "def splits(df, mode= 1):\n",
    "    if mode == 1:\n",
    "        y = df[\"Class\"]\n",
    "    elif mode == 0:\n",
    "        y = df[\"Value\"]\n",
    "    else:\n",
    "        raise ValueError(f\"{mode} is not a valid key. Use mode= 1 (clf) or mode= 0 (reg)\")\n",
    "\n",
    "    X = df[\"Fingerprint\"]\n",
    "    X_remainder, X_test, y_remainder, y_test = train_test_split(X, y, test_size= 0.2)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_remainder, y_remainder, test_size= 0.25)\n",
    "\n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val\n",
    "\n",
    "def gen_fps(df, fingerprint_type=\"Morgan\", resolution=1024):\n",
    "    if \"SMILES\" not in df.columns:\n",
    "        raise ValueError(\"DataFrame must contain a 'SMILES' column.\")\n",
    "    \n",
    "    smiles = df[\"SMILES\"].tolist()\n",
    "    mols = [Chem.MolFromSmiles(s) for s in smiles if Chem.MolFromSmiles(s)]\n",
    "    del smiles\n",
    "    if fingerprint_type == 'Morgan':\n",
    "        generator = rdFingerprintGenerator.GetMorganGenerator(radius=3, fpSize=resolution)\n",
    "    elif fingerprint_type == 'AtomPair':\n",
    "        generator = rdFingerprintGenerator.GetAtomPairGenerator(fpSize=resolution)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported fingerprint type: {fingerprint_type}\")\n",
    "    fingerprints = generator.GetFingerprints(mols)\n",
    "    del mols\n",
    "\n",
    "    return fingerprints\n",
    "    del fingerprints\n",
    "\n",
    "def hyper_params(clf, params, scoring, X, y):\n",
    "    grid = GridSearchCV(clf, params, cv= 5, scoring= scoring)\n",
    "    grid.fit(X, y)\n",
    "    cv_results = grid.cv_results_\n",
    "    all_scores = cv_results['mean_test_score']\n",
    "    best_index = grid.best_index_\n",
    "    fold_scores = [\n",
    "        cv_results['split0_test_score'][best_index], cv_results['split1_test_score'][best_index], cv_results['split2_test_score'][best_index], cv_results['split3_test_score'][best_index], cv_results['split4_test_score'][best_index]\n",
    "    ]\n",
    "    \n",
    "    return grid.best_params_, grid.best_score_, fold_scores\n",
    "    del grid\n",
    "\n",
    "def run_friedman_nemenyi(metric_matrix, metric_name):\n",
    "    print(f\"\\nTesting: {metric_name}\")\n",
    "    stat, p = friedmanchisquare(*[metric_matrix[:, i] for i in range(metric_matrix.shape[1])])\n",
    "    print(f\"Friedman test statistic: {stat:.4f}, p-value: {p:.4f}\")\n",
    "    if p < 0.05:\n",
    "        print(f\"Significant differences found. \\n\\nNemenyi post-hoc test for {metric_name}:\")\n",
    "        df = pd.DataFrame(metric_matrix, columns=models)\n",
    "        nemenyi = sp.posthoc_nemenyi_friedman(df)\n",
    "        print(nemenyi)\n",
    "    else:\n",
    "        print(\"No significant differences found.\")\n",
    "\n",
    "def create_ensemble_model(models_dict):\n",
    "    estimators = [(name, clf) for name, clf in models_dict.items()]\n",
    "    ensemble_clf = VotingClassifier(\n",
    "        estimators=estimators,\n",
    "        voting=\"soft\"\n",
    "    )\n",
    "    \n",
    "    return ensemble_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76f1e505-82e5-4779-ad34-8fd5761cb978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lists, dicts, dataframes etc.\n",
    "\n",
    "# Light Gradient Boosting (LGB)\n",
    "clfLGB = LGBMClassifier(random_state = 42)\n",
    "regLGB = LGBMRegressor(random_state = 42)\n",
    "LGB_params = {\n",
    "    \"num_leaves\": [10, 50, 100],\n",
    "    \"max_depth\": [-1, 2, 5],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"feature_fraction\": [0.1, 0.5, 1]\n",
    "}\n",
    "# 3x3x3x3 training grid - 81 runs\n",
    "\n",
    "# Extreme Gradient Boosting (XGB)\n",
    "clfXGB = XGBClassifier(random_state = 42)\n",
    "regXGB = XGBRegressor(random_state = 42)\n",
    "XGB_params = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [-1, 2, 5],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"subsample\": [0.1, 0.5, 1.0]\n",
    "}\n",
    "# 3x3x3x3 training grid - 81 runs\n",
    "\n",
    "# Multilayer Perceptron (MLP)\n",
    "clfMLP = MLPClassifier(random_state = 42)\n",
    "regMLP = MLPRegressor(random_state = 42)\n",
    "MLP_params = {\n",
    "    \"hidden_layer_sizes\": [(100,), (10,10)],\n",
    "    \"learning_rate_init\": [0.001, 0.002, 0.005],\n",
    "    \"alpha\": [0.0001, 0.0002]\n",
    "}\n",
    "# 2x3x2 training grid - 12 runs\n",
    "\n",
    "# Random Forest (RF)\n",
    "clfRF = RandomForestClassifier(random_state = 42)\n",
    "regRF = RandomForestRegressor(random_state = 42)\n",
    "RF_params = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [None, 2, 5],\n",
    "    \"max_features\": [10, 100],\n",
    "    \"min_samples_split\": [2, 5, 7]\n",
    "}\n",
    "# 3x3x3x3 training grid - 81 runs\n",
    "\n",
    "# Support Vector Machine (SVM)\n",
    "clfSVM = SVC()\n",
    "regSVM = SVR()\n",
    "SVM_params = {\n",
    "    \"C\": [1, 0.5, 2, 5],\n",
    "    \"kernel\": [\"linear\", \"rbf\"]\n",
    "}\n",
    "# 4x2 training grid - 8 runs\n",
    "\n",
    "# CatBoost (CB)\n",
    "clfCB = CatBoostClassifier(random_seed = 42)\n",
    "regCB = CatBoostRegressor(random_seed = 42)\n",
    "CB_params = {\n",
    "    \"iterations\": [500],\n",
    "    \"depth\": [2, 5, 7],\n",
    "    \"learning_rate\": [0.01, 0.02, 0.03],\n",
    "    \"l2_leaf_reg\": [1.0, 2.0, 3.0]\n",
    "}\n",
    "# 3x3x3x3 training grid - 81 runs\n",
    "\n",
    "classifiers = {\n",
    "    \"LGB\": LGBMClassifier(random_state= 42, **LGB_params),\n",
    "    \"XGB\": XGBClassifier(random_state= 42, **XGB_params),\n",
    "    \"MLP\": MLPClassifier(random_state= 42, **MLP_params),\n",
    "    \"RF\": RandomForestClassifier(random_state= 42, **RF_params),\n",
    "    \"SVC\": SVC(**SVM_params),\n",
    "    \"CB\": CatBoostClassifier(random_seed= 42, **CB_params)\n",
    "}\n",
    "\n",
    "regressors = {\n",
    "    \"LGB\": LGBMRegressor(random_state= 42, **LGB_params),\n",
    "    \"XGB\": XGBRegressor(random_state= 42, **XGB_params),\n",
    "    \"MLP\": MLPRegressor(random_state= 42, **MLP_params),\n",
    "    \"RF\": RandomForestRegressor(random_state= 42, **RF_params),\n",
    "    \"SVC\": SVR(**SVM_params),\n",
    "    \"CB\": CatBoostRegressor(random_seed= 42, **CB_params)\n",
    "}\n",
    "\n",
    "models=  [\"LGB\", \"XGB\", \"MLP\", \"RF\", \"SVM\", \"CatBoost\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd204e9b-b552-44ba-95de-d882f494cd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1  Complete\n",
      "Iteration  2  Complete\n",
      "Iteration  3  Complete\n",
      "Iteration  4  Complete\n",
      "Iteration  5  Complete\n",
      "Iteration  6  Complete\n",
      "Iteration  7  Complete\n",
      "Iteration  8  Complete\n",
      "Iteration  9  Complete\n",
      "Iteration  10  Complete\n",
      "Iteration  11  Complete\n",
      "Iteration  12  Complete\n",
      "Iteration  13  Complete\n",
      "Iteration  14  Complete\n",
      "Iteration  15  Complete\n",
      "Iteration  16  Complete\n",
      "Iteration  17  Complete\n",
      "Iteration  18  Complete\n",
      "Iteration  19  Complete\n",
      "Iteration  20  Complete\n",
      "Iteration  21  Complete\n",
      "Iteration  22  Complete\n",
      "Iteration  23  Complete\n",
      "Iteration  24  Complete\n",
      "Iteration  25  Complete\n",
      "Split  1  Complete\n",
      "Split  2  Complete\n",
      "Split  3  Complete\n",
      "Split  4  Complete\n",
      "Split  5  Complete\n",
      "Split  6  Complete\n",
      "Split  7  Complete\n",
      "Split  8  Complete\n",
      "Split  9  Complete\n",
      "Split  10  Complete\n",
      "Split  11  Complete\n",
      "Split  12  Complete\n",
      "Split  13  Complete\n",
      "Split  14  Complete\n",
      "Split  15  Complete\n"
     ]
    }
   ],
   "source": [
    "df_KDR = df1[df1[\"Kinase_name\"] == \"KDR\"]\n",
    "df_FLT1 = df1[df1[\"Kinase_name\"] == \"FLT1\"]\n",
    "df_p110a = df1[df1[\"Kinase_name\"] == \"p110a\"]\n",
    "df_JAK1 = df1[df1[\"Kinase_name\"] == \"JAK1\"]\n",
    "df_JAK2 = df1[df1[\"Kinase_name\"] == \"JAK2\"]\n",
    "df_ErbB2 = df1[df1[\"Kinase_name\"] == \"ErbB2\"]\n",
    "df_EGFR = df1[df1[\"Kinase_name\"] == \"EGFR\"]\n",
    "df_PIM1 = df1[df1[\"Kinase_name\"] == \"PIM1\"]\n",
    "df_ROCK1 = df1[df1[\"Kinase_name\"] == \"ROCK1\"]\n",
    "df_ABL1 = df1[df1[\"Kinase_name\"] == \"ABL1\"]\n",
    "\n",
    "df_TK = df1[df1[\"Kinase_group\"] == \"TK\"]\n",
    "df_CMGC = df1[df1[\"Kinase_group\"] == \"CMGC\"]\n",
    "df_AGC = df1[df1[\"Kinase_group\"] == \"AGC\"]\n",
    "df_CAMK = df1[df1[\"Kinase_group\"] == \"CAMK\"]\n",
    "df_Atypical = df1[df1[\"Kinase_group\"] == \"Atypical\"]\n",
    "\n",
    "kinase_dfs = [\n",
    "    df_KDR,\n",
    "    df_FLT1,\n",
    "    df_p110a,\n",
    "    df_JAK1,\n",
    "    df_JAK2,\n",
    "    df_ErbB2,\n",
    "    df_EGFR,\n",
    "    df_PIM1,\n",
    "    df_ROCK1,\n",
    "    df_ABL1,\n",
    "    df_TK,\n",
    "    df_CMGC,\n",
    "    df_AGC,\n",
    "    df_CAMK,\n",
    "    df_Atypical\n",
    "]\n",
    "cleaned_kinase_dfs1 = [clean_df1(i) for i in kinase_dfs]\n",
    "del kinase_dfs\n",
    "\n",
    "df2 = clean_df2(df2)\n",
    "\n",
    "cleaned_kinase_dfs2 = []\n",
    "z = 1\n",
    "for i in cleaned_kinase_dfs1:\n",
    "    i[\"Fingerprint\"] = gen_fps(i, \"Morgan\", 2048)\n",
    "    cleaned_kinase_dfs2.append(i)\n",
    "    print(\"Iteration \",z,\" Complete\") # for my sanity, waste of computation\n",
    "    z+=1\n",
    "del cleaned_kinase_dfs1\n",
    "\n",
    "# Necessary to stop jupyter from breaking (too much data per package -> break into smaller packages)\n",
    "dfs = np.array_split(df2, 10)\n",
    "cleaned_dfs = []\n",
    "for i in dfs:\n",
    "    i[\"Fingerprint\"] = gen_fps(i, \"Morgan\", 2048)\n",
    "    cleaned_dfs.append(i)\n",
    "    print(\"Iteration \",z,\" Complete\")\n",
    "    z+=1\n",
    "del dfs\n",
    "df2 = pd.concat([i for i in cleaned_dfs], axis= 0)\n",
    "del cleaned_dfs, z\n",
    "\n",
    "for i in cleaned_kinase_dfs2:\n",
    "    validate_df(i)\n",
    "validate_df(df2)\n",
    "\n",
    "dataframes = [pd.concat([i, df2], axis= 0, ignore_index= True) for i in cleaned_kinase_dfs2]\n",
    "del df2, cleaned_kinase_dfs2\n",
    "\n",
    "X= 1\n",
    "df_KDR = dataframes[0] # Reassign to dataframe\n",
    "X_train_KDR_class, X_test_KDR_class, X_val_KDR_class, y_train_KDR_class, y_test_KDR_class, y_val_KDR_class = splits(df_KDR, mode= 1) # Classification\n",
    "X_train_KDR_reg, X_test_KDR_reg, X_val_KDR_reg, y_train_KDR_reg, y_test_KDR_reg, y_val_KDR_reg = splits(df_KDR, mode= 0) # Regression\n",
    "print(\"Split \", X, \" Complete\")\n",
    "X +=1\n",
    "df_FLT1 = dataframes[1]\n",
    "X_train_FLT1_class, X_test_FLT1_class, X_val_FLT1_class, y_train_FLT1_class, y_test_FLT1_class, y_val_FLT1_class = splits(df_KDR, mode= 1)\n",
    "X_train_FLT1_reg, X_test_FLT1_reg, X_val_FLT1_reg, y_train_FLT1_reg, y_test_FLT1_reg, y_val_FLT1_reg = splits(df_KDR, mode= 0)\n",
    "print(\"Split \", X, \" Complete\")\n",
    "X +=1\n",
    "df_p110a = dataframes[2]\n",
    "X_train_p110a_class, X_test_p110a_class, X_val_p110a_class, y_train_p110a_class, y_test_p110a_class, y_val_p110a_class = splits(df_KDR, mode= 1)\n",
    "X_train_p110a_reg, X_test_p110a_reg, X_val_p110a_reg, y_train_p110a_reg, y_test_p110a_reg, y_val_p110a_reg = splits(df_KDR, mode= 0)\n",
    "print(\"Split \", X, \" Complete\")\n",
    "X +=1\n",
    "df_JAK1 = dataframes[3]\n",
    "X_train_JAK1_class, X_test_JAK1_class, X_val_JAK1_class, y_train_JAK1_class, y_test_JAK1_class, y_val_JAK1_class = splits(df_KDR, mode= 1)\n",
    "X_train_JAK1_reg, X_test_JAK1_reg, X_val_JAK1_reg, y_train_JAK1_reg, y_test_JAK1_reg, y_val_JAK1_reg = splits(df_KDR, mode= 0)\n",
    "print(\"Split \", X, \" Complete\")\n",
    "X +=1\n",
    "df_JAK2 = dataframes[4]\n",
    "X_train_JAK2_class, X_test_JAK2_class, X_val_JAK2_class, y_train_JAK2_class, y_test_JAK2_class, y_val_JAK2_class = splits(df_KDR, mode= 1)\n",
    "X_train_JAK2_reg, X_test_JAK2_reg, X_val_JAK2_reg, y_train_JAK2_reg, y_test_JAK2_reg, y_val_JAK2_reg = splits(df_KDR, mode= 0)\n",
    "print(\"Split \", X, \" Complete\")\n",
    "X +=1\n",
    "df_ErbB2 = dataframes[5]\n",
    "X_train_ErbB2_class, X_test_ErbB2_class, X_val_ErbB2_class, y_train_ErbB2_class, y_test_ErbB2_class, y_val_ErbB2_class = splits(df_KDR, mode= 1)\n",
    "X_train_ErbB2_reg, X_test_ErbB2_reg, X_val_ErbB2_reg, y_train_ErbB2_reg, y_test_ErbB2_reg, y_val_ErbB2_reg = splits(df_KDR, mode= 0)\n",
    "print(\"Split \", X, \" Complete\")\n",
    "X +=1\n",
    "df_EGFR = dataframes[6]\n",
    "X_train_EGFR_class, X_test_EGFR_class, X_val_EGFR_class, y_train_EGFR_class, y_test_EGFR_class, y_val_EGFR_class = splits(df_KDR, mode= 1)\n",
    "X_train_EGFR_reg, X_test_EGFR_reg, X_val_EGFR_reg, y_train_EGFR_reg, y_test_EGFR_reg, y_val_EGFR_reg = splits(df_KDR, mode= 0)\n",
    "print(\"Split \", X, \" Complete\")\n",
    "X +=1\n",
    "df_PIM1 = dataframes[7]\n",
    "X_train_PIM1_class, X_test_PIM1_class, X_val_PIM1_class, y_train_PIM1_class, y_test_PIM1_class, y_val_PIM1_class = splits(df_KDR, mode= 1)\n",
    "X_train_PIM1_reg, X_test_PIM1_reg, X_val_PIM1_reg, y_train_PIM1_reg, y_test_PIM1_reg, y_val_PIM1_reg = splits(df_KDR, mode= 0)\n",
    "print(\"Split \", X, \" Complete\")\n",
    "X +=1\n",
    "df_ROCK1 = dataframes[8]\n",
    "X_train_ROCK1_class, X_test_ROCK1_class, X_val_ROCK1_class, y_train_ROCK1_class, y_test_ROCK1_class, y_val_ROCK1_class = splits(df_KDR, mode= 1)\n",
    "X_train_ROCK1_reg, X_test_ROCK1_reg, X_val_ROCK1_reg, y_train_ROCK1_reg, y_test_ROCK1_reg, y_val_ROCK1_reg = splits(df_KDR, mode= 0)\n",
    "print(\"Split \", X, \" Complete\")\n",
    "X +=1\n",
    "df_ABL1 = dataframes[9]\n",
    "X_train_ABL1_class, X_test_ABL1_class, X_val_ABL1_class, y_train_ABL1_class, y_test_ABL1_class, y_val_ABL1_class = splits(df_KDR, mode= 1)\n",
    "X_train_ABL1_reg, X_test_ABL1_reg, X_val_ABL1_reg, y_train_ABL1_reg, y_test_ABL1_reg, y_val_ABL1_reg = splits(df_KDR, mode= 0)\n",
    "print(\"Split \", X, \" Complete\")\n",
    "X +=1\n",
    "df_TK = dataframes[10]\n",
    "X_train_TK_class, X_test_TK_class, X_val_TK_class, y_train_TK_class, y_test_TK_class, y_val_TK_class = splits(df_KDR, mode= 1)\n",
    "X_train_TK_reg, X_test_TK_reg, X_val_TK_reg, y_train_TK_reg, y_test_TK_reg, y_val_TK_reg = splits(df_KDR, mode= 0)\n",
    "print(\"Split \", X, \" Complete\")\n",
    "X +=1\n",
    "df_CMGC = dataframes[11]\n",
    "X_train_CMGC_class, X_test_CMGC_class, X_val_CMGC_class, y_train_CMGC_class, y_test_CMGC_class, y_val_CMGC_class = splits(df_KDR, mode= 1)\n",
    "X_train_CMGC_reg, X_test_CMGC_reg, X_val_CMGC_reg, y_train_CMGC_reg, y_test_CMGC_reg, y_val_CMGC_reg = splits(df_KDR, mode= 0)\n",
    "print(\"Split \", X, \" Complete\")\n",
    "X +=1\n",
    "df_AGC = dataframes[12]\n",
    "X_train_AGC_class, X_test_AGC_class, X_val_AGC_class, y_train_AGC_class, y_test_AGC_class, y_val_AGC_class = splits(df_KDR, mode= 1)\n",
    "X_train_AGC_reg, X_test_AGC_reg, X_val_AGC_reg, y_train_AGC_reg, y_test_AGC_reg, y_val_AGC_reg = splits(df_KDR, mode= 0)\n",
    "print(\"Split \", X, \" Complete\")\n",
    "X +=1\n",
    "df_CAMK = dataframes[13]\n",
    "X_train_CAMK_class, X_test_CAMK_class, X_val_CAMK_class, y_train_CAMK_class, y_test_CAMK_class, y_val_CAMK_class = splits(df_KDR, mode= 1)\n",
    "X_train_CAMK_reg, X_test_CAMK_reg, X_val_CAMK_reg, y_train_CAMK_reg, y_test_CAMK_reg, y_val_CAMK_reg = splits(df_KDR, mode= 0)\n",
    "print(\"Split \", X, \" Complete\")\n",
    "X +=1\n",
    "df_Atypical = dataframes[14]\n",
    "X_train_Atypical_class, X_test_Atypical_class, X_val_Atypical_class, y_train_Atypical_class, y_test_Atypical_class, y_val_Atypical_class = splits(df_KDR, mode= 1)\n",
    "X_train_Atypical_reg, X_test_Atypical_reg, X_val_Atypical_reg, y_train_Atypical_reg, y_test_Atypical_reg, y_val_Atypical_reg = splits(df_KDR, mode= 0)\n",
    "print(\"Split \", X, \" Complete\")\n",
    "del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec4d9c0-e208-460d-9b97-2facf85c9216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing for Speed\n",
    "\n",
    "# RandomForestClassifier(n_jobs = -1) -> use all available cores. default is set to n_jobs = None -> one core (no parallel processing)\n",
    "# Works for XGB, LGB and (conditionally) SVM. CatBoost uses thread_count = -1 instead. Not supported on MLP\n",
    "# On this system (AI7 350 & 16gb ram), (should) increase speed by ~8x\n",
    "# Note: do not run on battery for this, automatically parks 12/16 threads (uses 4 single-threaded cores) <- in the case of my laptop\n",
    "\n",
    "clfRF = RandomForestClassifier(random_state = 42, n_jobs= -1)\n",
    "regRF = RandomForestRegressor(random_state = 42, n_jobs= -1)\n",
    "RF_params = {\n",
    "    \"n_estimators\": [50, 100],\n",
    "    \"max_depth\": [None],\n",
    "    \"max_features\": [10],\n",
    "    \"min_samples_split\": [2]\n",
    "}\n",
    "best_params, best_score, best_scores = hyper_params(clfSVM, SVM_params, \"accuracy\", np.stack(X_val_ABL1_class), y_val_ABL1_class,)\n",
    "#^runs in ~55 mins (running 8 param combos in 2-fold, wtf??????)\n",
    "#running for literally one change in parameters (50/100 estimators): start 19.29, end "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
